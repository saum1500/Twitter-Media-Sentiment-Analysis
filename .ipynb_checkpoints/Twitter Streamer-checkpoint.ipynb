{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import tweepy\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using python object serialization using pickle to load the credentials from a different notebook with the twitter credentials from my developer account\n",
    "credentials = pickle.load(open(\"save.credentials\", \"rb\"))\n",
    "# loading the credentials\n",
    "ACCESS_TOKEN = credentials[0]\n",
    "ACCESS_TOKEN_SECRET = credentials[1]\n",
    "API_KEY = credentials[2]\n",
    "API_SECRET_KEY = credentials[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating authentication for twitter\n",
    "def authenticate_twitter():\n",
    "    auth = tweepy.OAuthHandler(API_KEY,API_SECRET_KEY)\n",
    "    auth.set_access_token(ACCESS_TOKEN,ACCESS_TOKEN_SECRET)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting media sources and words of relevance \n",
    "media_sources = pickle.load(open(\"save.media\", \"rb\"))\n",
    "# These are the words that we are looking to match with the tweets\n",
    "words_relevance = [\"Black+lives+matter\",\"racism\", \"police+brutality\"]\n",
    "# getting required hashtags and dates\n",
    "date_since = \"2020-05-25\"\n",
    "full_data_frame = pd.DataFrame(columns =[\"Tweet\", \"ID\", \"Retweet count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have to breakdown our collection into smaller word lists because the API call restrictions from twitter, hence we divide our analysis into three sections collected over a break of fifteen minutes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calls the api\n",
    "authenticate_twitter()\n",
    "# we have two nested loops in which we iterate through the media channel and the tweet\n",
    "for media in media_sources:\n",
    "    for word in words_relevance:\n",
    "        # we make a search word by specifying the username and keywords and removing retweets in this count\n",
    "        search_word = \"from:\"+media+ \" \"+ word+ \" -filter:retweets\"\n",
    "        # tweepy's function for gathering the dataset\n",
    "        tweets = tweepy.Cursor(api.search, q = search_word, lang = \"en\",since = date_since).items(1000)\n",
    "        # extracting the dataset\n",
    "        tweet_details = [[tweet.text, tweet.user.screen_name, tweet.retweet_count] for tweet in tweets]\n",
    "        tweet_df = pd.DataFrame(data=tweet_details, columns=[\"Tweet\", \"ID\", \"Retweet count\"])\n",
    "        tweet_df = tweet_df.drop_duplicates()\n",
    "        full_data_frame = pd.concat([full_data_frame,tweet_df], ignore_index = True)\n",
    "full_data_frame.to_csv(\"Tweet Data Stored, 1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>ID</th>\n",
       "      <th>Retweet count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\"The next stage is the counter-strike by those...</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@DannyBoyle87 Black Lives Matter: BBC says sho...</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A new study which assessed data from 315 US ci...</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>✉️ Letters to the Editor: 'As a BAME citizen, ...</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Independent schools in the UK plan to \"teach b...</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet         ID Retweet count\n",
       "0  \"The next stage is the counter-strike by those...  Telegraph             3\n",
       "1  @DannyBoyle87 Black Lives Matter: BBC says sho...  Telegraph             5\n",
       "2  A new study which assessed data from 315 US ci...  Telegraph            18\n",
       "3  ✉️ Letters to the Editor: 'As a BAME citizen, ...  Telegraph            10\n",
       "4  Independent schools in the UK plan to \"teach b...  Telegraph             7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(757, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(full_data_frame.head(), full_data_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_relevance = [\"george+floyd\",\"breonna+taylor\",\"ahmaud+arbery\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for media in media_sources:\n",
    "    for word in words_relevance:\n",
    "        search_word = \"from:\"+media+ \" \"+ word+ \" -filter:retweets\"\n",
    "        tweets = tweepy.Cursor(api.search, q = search_word, lang = \"en\",since = date_since).items(1000)\n",
    "        tweet_details = [[tweet.text, tweet.user.screen_name, tweet.retweet_count] for tweet in tweets]\n",
    "        tweet_df = pd.DataFrame(data=tweet_details, columns=[\"Tweet\", \"ID\", Retweet count\"])\n",
    "        tweet_df = tweet_df.drop_duplicates()\n",
    "        full_data_frame = pd.concat([full_data_frame,tweet_df], ignore_index = True)\n",
    "full_data_frame.to_csv(\"Tweet Data Stored, 2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(full_data_frame.head(), full_data_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_relevance = [\"police+protest\",\"defund+police\",\"minnesota+police\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for media in media_sources:\n",
    "    for word in words_relevance:\n",
    "        search_word = \"from:\"+media+ \" \"+ word+ \" -filter:retweets\"\n",
    "        tweets = tweepy.Cursor(api.search, q = search_word, lang = \"en\",since = date_since).items(1000)\n",
    "        tweet_details = [[tweet.text, tweet.user.screen_name, tweet.retweet_count] for tweet in tweets]\n",
    "        tweet_df = pd.DataFrame(data=tweet_details, columns=[\"Tweet\", \"ID\", \"Retweet count\"])\n",
    "        tweet_df = tweet_df.drop_duplicates()\n",
    "        full_data_frame = pd.concat([full_data_frame,tweet_df], ignore_index = True)\n",
    "full_data_frame.to_csv(\"Tweet Data Stored, 3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(full_data_frame.head(), full_data_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(full_data_frame, open(\"save.fulldata\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
